{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.metrics import log_loss #evaluation metric\n",
    "\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "features = pd.read_csv('data_features.csv',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data \n",
    "Crime rates in New York City spiked in the 1980s and early 1990s as the crack epidemic hit, but they have been dropping since 1991, and, as of 2017, they are among the lowest of major cities in the United States. During the 1990s, the New York City Police Department (NYPD) adopted CompStat, broken windows policing, and other strategies in a major effort to reduce crime. The city's dramatic drop in crime has been variously attributed to a number of factors, including the end of the crack epidemic, the legalization of abortion, and the decline of lead poisoning in children.\n",
    "\n",
    "Today, the city is known more for its fashion and tourism than its criminal past. But, with rising wealth inequality, housing shortages, and a number of tourists flocking the city, there is still no scarcity of crime in the Big Apple.\n",
    "\n",
    "This dataset provides nearly 40 years of crime reports from across all of NYC's neighborhoods. There is 6.5 million recorded complaints and 35 fields describing date, time, place of occurance crime and various other data including age, sex and race of suspects and victims. \n",
    "\n",
    "Detailed information about dataset can be downloaded [here](https://data.cityofnewyork.us/api/views/qgea-i56i/files/b21ec89f-4d7b-494e-b2e9-f69ae7f4c228?download=true&filename=NYPD_Complaint_Incident_Level_Data_Footnotes.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "The goal of this project is to help NYPD allocate their resources in an efficient way. By predicting the most probable type of crime that is going to happen in specific location based on date and time we can either prevent or be prepared to react to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms used\n",
    "\n",
    "#### 1. Random Forest Classifier\n",
    "    An ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set.\n",
    "#### 2) Extra Tree Classifier\n",
    "    An extremely randomized tree classifier. Extra-trees differ from classic decision trees in the way they are built. When looking for the best split to separate the samples of a node into two groups, random splits are drawn for each of the max_features randomly selected features and the best split among those is chosen. When max_features is set 1, this amounts to building a totally random decision tree.\n",
    "#### 3) Bernoulli Naïve Bayes\n",
    "    In machine learning, Naïve Bayes classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong (naive) independence assumptions between the features. The Bernoulli Naïve Bayes classifier assumes that all features are binary such that they take only two values (e.g. a nominal categorical feature that has been one-hot encoded).\n",
    "#### 4) LightGBM\n",
    "    A fast, distributed, high performance gradient boosting (GBT, GBDT, GBRT, GBM or MART) framework based on decision tree algorithms, used for ranking, classification and many other machine learning tasks. Project of Microsoft.\n",
    "#### 5) CatBoost\n",
    "    CatBoost is an algorithm for gradient boosting on decision trees. It is developed by Yandex, and is for search, recommendation systems, personal assistance, self-driving cars, weather prediction..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric\n",
    "Models are evaluated using the multi-class logarithmic loss. Each incident has been labeled with one true class. For each incident, you must submit a set of predicted probabilities (one for every class). The formula is:\n",
    "\n",
    "\\begin{equation*}\n",
    "logloss = -\\frac{1}{N}\\sum_{i=1}^N \\sum_{j=1}^M y_{ij} log(p_{ij})\n",
    "\\end{equation*}\n",
    "\n",
    "where N is the number of cases in the test set, M is the number of class labels, log is the natural logarithm, $y_{ij}$ is 1 if observation i is in class j and 0 otherwise, and $p_{ij}$ is the predicted probability that observation i belongs to class j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Models\n",
    "| Algorithms | Parameters | Logloss |\n",
    "| - | - | - |\n",
    "| Random Forest | Default Scikit-Learn Parameters | 15.75366 |\n",
    "| Extra tree classifier | Default Scikit-Learn Parameters | 17.76022 |\n",
    "| BernoulliNB | Default Scikit-Learn Parameters | 2.66776 |\n",
    "| LightGBM | Default Scikit-Learn Parameters | 7.72007 |\n",
    "| Catboost | Default Scikit-Learn Parameters | / |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BORO_NM</th>\n",
       "      <th>Year</th>\n",
       "      <th>n_days</th>\n",
       "      <th>LL_X</th>\n",
       "      <th>LL_Y</th>\n",
       "      <th>LL_Z</th>\n",
       "      <th>Hour_X</th>\n",
       "      <th>Hour_Y</th>\n",
       "      <th>Month_X</th>\n",
       "      <th>Month_Y</th>\n",
       "      <th>Weekday_X</th>\n",
       "      <th>Weekday_Y</th>\n",
       "      <th>Minute_X</th>\n",
       "      <th>Minute_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997946</td>\n",
       "      <td>-0.114243</td>\n",
       "      <td>-0.992967</td>\n",
       "      <td>0.031071</td>\n",
       "      <td>-0.269797</td>\n",
       "      <td>0.962917</td>\n",
       "      <td>0.540641</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.507666</td>\n",
       "      <td>0.861554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.180968</td>\n",
       "      <td>-0.017943</td>\n",
       "      <td>-0.993626</td>\n",
       "      <td>0.111291</td>\n",
       "      <td>-0.631088</td>\n",
       "      <td>-0.775711</td>\n",
       "      <td>0.989821</td>\n",
       "      <td>-0.142315</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.211383</td>\n",
       "      <td>0.977403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.460749</td>\n",
       "      <td>-0.013314</td>\n",
       "      <td>-0.998910</td>\n",
       "      <td>-0.044733</td>\n",
       "      <td>0.942261</td>\n",
       "      <td>-0.334880</td>\n",
       "      <td>-0.755750</td>\n",
       "      <td>-0.654861</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.314077</td>\n",
       "      <td>0.949398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.483113</td>\n",
       "      <td>-0.116816</td>\n",
       "      <td>-0.992079</td>\n",
       "      <td>0.046187</td>\n",
       "      <td>-0.997669</td>\n",
       "      <td>-0.068242</td>\n",
       "      <td>-0.540641</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.314077</td>\n",
       "      <td>0.949398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007987</td>\n",
       "      <td>-0.388155</td>\n",
       "      <td>-0.863137</td>\n",
       "      <td>0.323002</td>\n",
       "      <td>-0.979084</td>\n",
       "      <td>0.203456</td>\n",
       "      <td>0.909632</td>\n",
       "      <td>0.415415</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BORO_NM      Year    n_days      LL_X      LL_Y      LL_Z    Hour_X  \\\n",
       "0        2  1.000000  0.997946 -0.114243 -0.992967  0.031071 -0.269797   \n",
       "1        3  0.181818  0.180968 -0.017943 -0.993626  0.111291 -0.631088   \n",
       "2        0  0.454545  0.460749 -0.013314 -0.998910 -0.044733  0.942261   \n",
       "3        2  0.454545  0.483113 -0.116816 -0.992079  0.046187 -0.997669   \n",
       "4        4  0.000000  0.007987 -0.388155 -0.863137  0.323002 -0.979084   \n",
       "\n",
       "     Hour_Y   Month_X   Month_Y     Weekday_X  Weekday_Y  Minute_X  Minute_Y  \n",
       "0  0.962917  0.540641  0.841254 -8.660254e-01        0.5  0.507666  0.861554  \n",
       "1 -0.775711  0.989821 -0.142315  8.660254e-01       -0.5  0.211383  0.977403  \n",
       "2 -0.334880 -0.755750 -0.654861  1.224647e-16       -1.0  0.314077  0.949398  \n",
       "3 -0.068242 -0.540641  0.841254  1.224647e-16       -1.0  0.314077  0.949398  \n",
       "4  0.203456  0.909632  0.415415  0.000000e+00        1.0  0.000000  1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_crime = features['crime']\n",
    "collist=features.columns.tolist()\n",
    "features[collist[:-1]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628013 269149\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(features,train_size=0.70)\n",
    "print(len(train) , len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[collist[:-1]]\n",
    "train_Y = train['crime']\n",
    "test_X = test[collist[:-1]]\n",
    "test_Y = test['crime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier (Logloss = 2.65477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier() \n",
    "y_score = forest.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.756650913980797"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_RF = np.array(forest.predict_proba(test_X))\n",
    "#evaluation metric : cross-entropy loss.\n",
    "log_loss(test_Y, predicted_RF, labels=category_crime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest...\")\n",
    "# Initialize a Random Forest classifier\n",
    "forest = RandomForestClassifier(n_estimators=300, max_depth=3, min_samples_leaf = 21) \n",
    "y_score = forest.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.655596381058399"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_RF = np.array(forest.predict_proba(test_X))\n",
    "#evaluation metric : cross-entropy loss.\n",
    "log_loss(test_Y, predicted_RF, labels=category_crime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra tree classifier  (Logloss = 2.60203)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "ETC_base_model = ExtraTreesClassifier()\n",
    "ETC_base_model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.938811624163748"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ETC = np.array(ETC_base_model.predict_proba(test_X))\n",
    "#evaluation metric : cross-entropy loss.\n",
    "log_loss(test_Y, predicted_ETC, labels=category_crime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=250, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
       "           oob_score=True, random_state=None, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "ETC_model = ExtraTreesClassifier(n_estimators=300, bootstrap=True,\n",
    "                             oob_score=True, n_jobs=-1,\n",
    "                             min_samples_leaf=250,\n",
    "                             verbose=1)\n",
    "ETC_model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:   20.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.603463746431742"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ETC = np.array(ETC_model.predict_proba(test_X))\n",
    "#evaluation metric : cross-entropy loss.\n",
    "log_loss(test_Y, predicted_ETC, labels=category_crime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BernoulliNB (Logloss = 2.66776)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6677834288498734"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "BNB_model = BernoulliNB(alpha=1, binarize=0.0)\n",
    "BNB_model.fit(train_X, train_Y)\n",
    "predicted_BNB = np.array(BNB_model.predict_proba(test_X))\n",
    "\n",
    "#evaluation metric : cross-entropy loss.\n",
    "log_loss(test_Y, predicted_BNB, labels=category_crime) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM (Logloss = 2.32498)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import *\n",
    "\n",
    "LGMB_base_model = LGBMClassifier() \n",
    "LGMB_base_model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.496990948993363"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_LGBM = np.array(LGMB_base_model.predict_proba(test_X))\n",
    "#evaluation metric : cross-entropy loss.\n",
    "log_loss(test_Y, predicted_LGBM, labels=category_crime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "train_data = lgb.Dataset(features[collist[:-1]], label=category_crime)\n",
    "\n",
    "params = {'boosting':'gbdt',\n",
    "          'objective':'multiclass',\n",
    "          'num_class':36,\n",
    "          'max_delta_step':0.9,\n",
    "          'min_data_in_leaf': 21,\n",
    "          'learning_rate': 0.4,\n",
    "          'max_bin': 465,\n",
    "          'num_leaves': 42,\n",
    "          'verbose' : 1,\n",
    "          'random_state' : 42}\n",
    "\n",
    "bst = lgb.train(params, train_data, 120)\n",
    "predicted_LGBM = bst.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.321165898856531"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation metric : cross-entropy loss.\n",
    "log_loss(test_Y, predicted_LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        41\n",
      "           2       1.00      1.00      1.00         8\n",
      "           3       0.94      0.10      0.18       628\n",
      "           4       0.21      0.27      0.24     28571\n",
      "           5       0.30      0.05      0.09      9473\n",
      "           6       1.00      1.00      1.00        17\n",
      "           7       0.24      0.20      0.21     27124\n",
      "           8       0.40      0.12      0.19      3204\n",
      "           9       0.24      0.45      0.32     16897\n",
      "          10       0.49      0.03      0.05      6362\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       0.52      0.02      0.05     10467\n",
      "          13       0.56      0.04      0.08      2718\n",
      "          14       0.97      0.84      0.90       106\n",
      "          15       0.30      0.16      0.20     23151\n",
      "          16       0.22      0.37      0.28     33684\n",
      "          17       1.00      1.00      1.00        12\n",
      "          18       0.44      0.26      0.33      3721\n",
      "          19       1.00      0.59      0.74       115\n",
      "          20       0.53      0.02      0.03      4774\n",
      "          21       1.00      1.00      1.00         9\n",
      "          22       0.64      0.02      0.04      6905\n",
      "          23       0.45      0.02      0.04     15166\n",
      "          24       0.56      0.05      0.10      5483\n",
      "          25       0.97      1.00      0.99        75\n",
      "          26       0.29      0.60      0.39     45143\n",
      "          27       0.87      0.02      0.04      1413\n",
      "          28       1.00      1.00      1.00        44\n",
      "          29       0.74      0.23      0.35       749\n",
      "          30       0.44      0.02      0.04      9929\n",
      "          31       0.47      0.93      0.63      3047\n",
      "          32       0.48      0.06      0.11      5866\n",
      "          33       0.77      0.09      0.17       860\n",
      "          34       1.00      1.00      1.00         5\n",
      "          35       0.42      0.11      0.18      3360\n",
      "\n",
      "   micro avg       0.27      0.27      0.27    269149\n",
      "   macro avg       0.65      0.44      0.44    269149\n",
      "weighted avg       0.33      0.27      0.22    269149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y, predicted_LGBM.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost (Logloss = 2.51918)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(iterations=200, learning_rate=0.4, l2_leaf_reg=3.5, depth=4, rsm=0.98, verbose=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: -2.9301103\ttotal: 4.91s\tremaining: 16m 16s\n",
      "8:\tlearn: -2.6228795\ttotal: 41s\tremaining: 14m 30s\n",
      "16:\tlearn: -2.6024027\ttotal: 1m 18s\tremaining: 14m 5s\n",
      "24:\tlearn: -2.5930120\ttotal: 1m 50s\tremaining: 12m 50s\n",
      "32:\tlearn: -2.5833234\ttotal: 2m 20s\tremaining: 11m 50s\n",
      "40:\tlearn: -2.5739141\ttotal: 2m 50s\tremaining: 11m\n",
      "48:\tlearn: -2.5680325\ttotal: 3m 20s\tremaining: 10m 17s\n",
      "56:\tlearn: -2.5612867\ttotal: 3m 50s\tremaining: 9m 38s\n",
      "64:\tlearn: -2.5547589\ttotal: 4m 20s\tremaining: 9m\n",
      "72:\tlearn: -2.5502937\ttotal: 4m 51s\tremaining: 8m 26s\n",
      "80:\tlearn: -2.5448002\ttotal: 5m 20s\tremaining: 7m 51s\n",
      "88:\tlearn: -2.5401469\ttotal: 5m 51s\tremaining: 7m 17s\n",
      "96:\tlearn: -2.5371028\ttotal: 6m 23s\tremaining: 6m 47s\n",
      "104:\tlearn: -2.5334642\ttotal: 6m 53s\tremaining: 6m 14s\n",
      "112:\tlearn: -2.5309808\ttotal: 7m 23s\tremaining: 5m 41s\n",
      "120:\tlearn: -2.5280410\ttotal: 7m 53s\tremaining: 5m 9s\n",
      "128:\tlearn: -2.5252740\ttotal: 8m 23s\tremaining: 4m 37s\n",
      "136:\tlearn: -2.5227480\ttotal: 8m 53s\tremaining: 4m 5s\n",
      "144:\tlearn: -2.5192599\ttotal: 9m 23s\tremaining: 3m 33s\n",
      "152:\tlearn: -2.5167738\ttotal: 9m 55s\tremaining: 3m 3s\n",
      "160:\tlearn: -2.5139013\ttotal: 10m 25s\tremaining: 2m 31s\n",
      "168:\tlearn: -2.5120961\ttotal: 10m 58s\tremaining: 2m\n",
      "176:\tlearn: -2.5095717\ttotal: 11m 29s\tremaining: 1m 29s\n",
      "184:\tlearn: -2.5070824\ttotal: 12m\tremaining: 58.4s\n",
      "192:\tlearn: -2.5056933\ttotal: 12m 29s\tremaining: 27.2s\n",
      "199:\tlearn: -2.5036154\ttotal: 12m 56s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1efc0d5e1d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5239235451381967"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_CB = np.array(model.predict_proba(test_X))\n",
    "\n",
    "#evaluation metric : cross-entropy loss.\n",
    "log_loss(test_Y, predicted_CB, labels=category_crime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.00      0.00      0.00        41\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00       628\n",
      "           4       0.17      0.20      0.18     28571\n",
      "           5       0.16      0.01      0.01      9473\n",
      "           6       0.00      0.00      0.00        17\n",
      "           7       0.17      0.14      0.15     27124\n",
      "           8       0.19      0.01      0.02      3204\n",
      "           9       0.20      0.36      0.26     16897\n",
      "          10       0.06      0.00      0.00      6362\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.35      0.01      0.01     10467\n",
      "          13       0.00      0.00      0.00      2718\n",
      "          14       0.00      0.00      0.00       106\n",
      "          15       0.22      0.06      0.10     23151\n",
      "          16       0.18      0.30      0.22     33684\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.25      0.13      0.17      3721\n",
      "          19       0.00      0.00      0.00       115\n",
      "          20       0.00      0.00      0.00      4774\n",
      "          21       0.00      0.00      0.00         9\n",
      "          22       0.00      0.00      0.00      6905\n",
      "          23       0.09      0.00      0.00     15166\n",
      "          24       0.44      0.04      0.07      5483\n",
      "          25       0.00      0.00      0.00        75\n",
      "          26       0.25      0.61      0.35     45143\n",
      "          27       0.00      0.00      0.00      1413\n",
      "          28       0.00      0.00      0.00        44\n",
      "          29       0.00      0.00      0.00       749\n",
      "          30       0.18      0.00      0.00      9929\n",
      "          31       0.31      0.33      0.32      3047\n",
      "          32       0.33      0.03      0.05      5866\n",
      "          33       0.00      0.00      0.00       860\n",
      "          34       0.00      0.00      0.00         5\n",
      "          35       0.32      0.07      0.12      3360\n",
      "\n",
      "   micro avg       0.21      0.21      0.21    269149\n",
      "   macro avg       0.11      0.06      0.06    269149\n",
      "weighted avg       0.19      0.21      0.16    269149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y, predicted_CB.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "| Algorithms | Parameters | Logloss |\n",
    "| - | - | - |\n",
    "| Random Forest | Custom Parameters | 2.65477 |\n",
    "| Extra tree classifier | Custom Parameters | 2.60203 |\n",
    "| BernoulliNB | Custom Parameters | 2.66776 |\n",
    "| LightGBM | Custom Parameters | 2.32040 |\n",
    "| Catboost | Custom Parameters | 2.51918 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BORO_NM</th>\n",
       "      <th>Year</th>\n",
       "      <th>n_days</th>\n",
       "      <th>LL_X</th>\n",
       "      <th>LL_Y</th>\n",
       "      <th>LL_Z</th>\n",
       "      <th>Hour_X</th>\n",
       "      <th>Hour_Y</th>\n",
       "      <th>Month_X</th>\n",
       "      <th>Month_Y</th>\n",
       "      <th>Weekday_X</th>\n",
       "      <th>Weekday_Y</th>\n",
       "      <th>Minute_X</th>\n",
       "      <th>Minute_Y</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>897147</th>\n",
       "      <td>3</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.764719</td>\n",
       "      <td>-0.036276</td>\n",
       "      <td>-0.994764</td>\n",
       "      <td>0.095549</td>\n",
       "      <td>-0.269797</td>\n",
       "      <td>0.962917</td>\n",
       "      <td>0.989821</td>\n",
       "      <td>-0.142315</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.507666</td>\n",
       "      <td>0.861554</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        BORO_NM      Year    n_days      LL_X      LL_Y      LL_Z    Hour_X  \\\n",
       "897147        3  0.818182  0.764719 -0.036276 -0.994764  0.095549 -0.269797   \n",
       "\n",
       "          Hour_Y   Month_X   Month_Y  Weekday_X  Weekday_Y  Minute_X  \\\n",
       "897147  0.962917  0.989821 -0.142315  -0.866025        0.5  0.507666   \n",
       "\n",
       "        Minute_Y  crime  \n",
       "897147  0.861554     26  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_prediction = features.loc[[897147]]\n",
    "data_for_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crime 10 is in category \"DANGEROUS DRUGS\" and borough 0 is Bronx. Model is reporting a high feature importance of BORO_NM and LL_Z features which aligns with our spatial analysis where we concluded that the highest concentration of dangerous drugs crimes is in Bronx. This makes us more confident about the validity of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "# Create object that can calculate shap values\n",
    "shap.initjs()\n",
    "#explainer = shap.TreeExplainer(bst).shap_values(data_for_prediction)\n",
    "\n",
    "%time shap_values = shap.TreeExplainer(bst).shap_values(features.loc[[897147]])\n",
    "# Calculate Shap values\n",
    "#shap_values = explainer.shap_values(data_for_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap.TreeExplainer(bst).expected_value[26], shap_values[26], features.loc[[897147]], link='logit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements\n",
    "We are sure there is space for improvement. Two additional techniques we would like to implement if there was the necessary time would be:\n",
    "\n",
    "- Introduce aditional data that shows economic, educational, and other socio-economic information for each borough. That way algorithms could notice and exploit patterns asociated with these factors and provide even better score. \n",
    "\n",
    "- Use embeddings or other processing techniques for the addresses. For example we could extract if an incident has happened in a block or a crossroad or a boulding etc. There are definitely some additional correlations between incident place and crime commited.\n",
    "\n",
    "- Use neural nets and combine the prediction with results from lgbm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
